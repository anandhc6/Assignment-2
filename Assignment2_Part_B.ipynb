{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_Part_B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandhc6/Assignment-2/blob/main/Assignment2_Part_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdrmeO4MRRsh",
        "outputId": "9bb267a3-9954-4ddd-f2c8-0f30163aa294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "To: /content/nature_12K.zip\n",
            "100% 3.82G/3.82G [00:18<00:00, 205MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Downloading the dataset as zip folder\n",
        "\n",
        "!gdown https://storage.googleapis.com/wandb_datasets/nature_12K.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAFVnuuvQFJJ"
      },
      "outputs": [],
      "source": [
        "# unzipping the datset\n",
        "\n",
        "!unzip -q nature_12K.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WaWNMqHdt1w",
        "outputId": "6a4deaac-5343-4e8b-c273-efa0b9aaa4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.11-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 45.3 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.8-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=da2f19454dbbb93d33bd34ee2de61505f9e65c344f42e0131af26ac64a877ea2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.8 setproctitle-1.2.2 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.11 yaspin-2.1.0\n"
          ]
        }
      ],
      "source": [
        "#Installing wand\n",
        "\n",
        "!pip install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jifqQnaUS5fI"
      },
      "outputs": [],
      "source": [
        "#Importing necessary packages\n",
        "\n",
        "import pathlib\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow.keras as tfk\n",
        "import os\n",
        "import glob\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from wandb.keras import WandbCallback\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQuOWlMgTARv"
      },
      "outputs": [],
      "source": [
        "# Data preperation\n",
        "\n",
        "def datagen(batch_size, augment_data):\n",
        "\n",
        "  Data_dir=pathlib.Path('inaturalist_12K') \n",
        "  # augment_data=False\n",
        "  train_path = os.path.join(Data_dir, \"train\")\n",
        "  test_path = os.path.join(Data_dir, \"val\")\n",
        "\n",
        "  if augment_data:\n",
        "    train_rawdata = ImageDataGenerator(rescale=1./255,\n",
        "                                      rotation_range=90,\n",
        "                                      zoom_range=0.2,\n",
        "                                      shear_range=0.2,\n",
        "                                      validation_split=0.1,\n",
        "                                      horizontal_flip=True)\n",
        "    test_rawdata = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  else:\n",
        "    train_rawdata = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "    test_rawdata = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  train_data = train_rawdata.flow_from_directory(\n",
        "      train_path, \n",
        "      target_size=(256, 256), \n",
        "      batch_size=batch_size, \n",
        "      subset=\"training\",\n",
        "      color_mode=\"rgb\",\n",
        "      class_mode='categorical',\n",
        "      shuffle=True,\n",
        "      seed=42\n",
        "      )\n",
        "  val_data = train_rawdata.flow_from_directory(\n",
        "      train_path, \n",
        "      target_size=(256, 256), \n",
        "      batch_size=batch_size, \n",
        "      subset=\"validation\",\n",
        "      color_mode=\"rgb\",\n",
        "      class_mode='categorical',\n",
        "      shuffle=True,\n",
        "      seed=42\n",
        "      )\n",
        "  test_data = test_rawdata.flow_from_directory(\n",
        "      test_path, \n",
        "      target_size=(256, 256), \n",
        "      batch_size=batch_size,\n",
        "      color_mode=\"rgb\",\n",
        "      class_mode='categorical',\n",
        "      shuffle=True,\n",
        "      seed=42\n",
        "      )\n",
        "  return  train_data, val_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJfm98bL-H4S"
      },
      "outputs": [],
      "source": [
        "# predefined models\n",
        "\n",
        "def define_model(model_name, activation_function_dense, dense_layer, dropout,image_size, pre_layer_train=None):\n",
        "  \n",
        "    #input_image_shape=(256,256,3)\n",
        "    ip_shape=(image_size, image_size, 3)\n",
        "    input_tens = tfk.Input(shape = ip_shape)\n",
        "\n",
        "    # adding pretrained model without the top dense layer\n",
        "    if model_name == 'ResNet50':\n",
        "      pretrained_model = tfk.applications.ResNet50(include_top = False, weights='imagenet',input_tensor = input_tens)\n",
        "    elif model_name == 'InceptionV3':\n",
        "      pretrained_model = tfk.applications.InceptionV3(include_top = False, weights='imagenet',input_tensor = input_tens)\n",
        "    elif model_name == 'InceptionResNetV2':\n",
        "      pretrained_model = tfk.applications.InceptionResNetV2(include_top = False, weights='imagenet',input_tensor = input_tens)\n",
        "    else:\n",
        "      pretrained_model = tfk.applications.Xception(include_top = False, weights='imagenet',input_tensor = input_tens)\n",
        "\n",
        "    for layer in pretrained_model.layers:\n",
        "      layer.trainable=False\n",
        "    \n",
        "    model = tfk.models.Sequential()\n",
        "    # pretrained model\n",
        "    model.add(pretrained_model)\n",
        "    # converting the feature map into a column vector\n",
        "    model.add(Flatten()) \n",
        "    # adding a dense layer\n",
        "    model.add(Dense(dense_layer, activation=activation_function_dense))\n",
        "    # dropout\n",
        "    model.add(Dropout(dropout)) \n",
        "    # softmax layer\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7iXUwpeBHiF"
      },
      "outputs": [],
      "source": [
        "#Function called by sweep\n",
        "\n",
        "def train():\n",
        "    activation_func_dense = \"relu\"\n",
        "    image_size=256\n",
        "    config_defaults = {\n",
        "            \"augment_data\": True,\n",
        "            \"batch_size\": 64,\n",
        "            \"dropout\": 0,\n",
        "            \"dense_layer\": 128,\n",
        "            \"layer_freeze\": 0,\n",
        "            \"pre_model\":\"ResNet50\"\n",
        "        }\n",
        "\n",
        "    # Initializing new wandb run and saving hyperparameters,inputs\n",
        "    wandb.init(config=config_defaults)\n",
        "    config = wandb.config\n",
        "\n",
        "    # Values obtained from wandb config(Sweep)\n",
        "    augment_data = config.augment_data\n",
        "    batch_size = config.batch_size\n",
        "    dropout = config.dropout\n",
        "    dense_layer = config.dense_layer\n",
        "    layer_freeze = config.layer_freeze\n",
        "    pre_model=config.pre_model\n",
        "\n",
        "    # Run name with hyperparameters\n",
        "    run_name = \"model_{}_aug_{}_bs_{}_drop_{}_dense_{}_freeze_{}\".format(pre_model, augment_data, batch_size, dropout, dense_layer, layer_freeze )\n",
        "    print(run_name)\n",
        "\n",
        "    # Data preperation\n",
        "    train_data, val_data, test_data =datagen(batch_size, augment_data)\n",
        "    print(\"Data Recieved\")\n",
        "    model=define_model(pre_model, activation_func_dense, dense_layer, dropout,image_size)\n",
        "    print(model.count_params())\n",
        "    print(\"Model Training done\")\n",
        "\n",
        "    # #Freeze all layers\n",
        "    # for layer in model.pretrained_model.layers:\n",
        "    #     layer.trainable=False\n",
        "    # #model.trainable=False\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    # Early Stopping \n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "\n",
        "    train_step_size = train_data.n//train_data.batch_size\n",
        "    print(train_step_size)\n",
        "    val_step_size = val_data.n//val_data.batch_size\n",
        "    print(val_step_size)\n",
        "\n",
        "    model_det = model.fit(train_data,\n",
        "          steps_per_epoch = train_step_size,\n",
        "          validation_data = val_data,\n",
        "          validation_steps = val_step_size,\n",
        "          epochs=10, \n",
        "          callbacks=[WandbCallback(data_type=\"image\", generator=val_data), earlyStopping, best_val_check],\n",
        "          verbose=2)\n",
        "    \n",
        "    #For fine tuning, unfreeze certain layers\n",
        "    if layer_freeze:\n",
        "      fine_tune=math.floor((layer_freeze/100.0)*len(model.layers))\n",
        "      for layer in model.layers[-fine_tune:]:\n",
        "        layer.trainable=True\n",
        "\n",
        "    print(\"Fine tuning\")\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    model_det_fine = model.fit(train_data,\n",
        "          steps_per_epoch = train_step_size,\n",
        "          validation_data = val_data,\n",
        "          validation_steps = val_step_size,\n",
        "          epochs=10, \n",
        "          callbacks=[WandbCallback(data_type=\"image\", generator=val_data), earlyStopping, best_val_check],\n",
        "          verbose=2)\n",
        "    \n",
        "    test_loss, test_acc = model.evaluate(test_data)\n",
        "    print('Test accuracy :', test_acc)\n",
        "    wandb.log({'test_accuracy': test_acc, 'test_loss': test_loss})\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "    wandb.run.finish()\n",
        "    return model_det_fine\n"
      ]
    }
  ]
}